> [!NOTE]
> This project is now largely unmaintained. However, while leaving this repo as-is, I will at some point plan for my future study, and this effort will probably be involved in, as I have more time. I will usually not accept pull reqs for now.

# scampages-datamine
my early effort on scraping and archiving scam, fake or disguising websites, especially those regarding attempts to scam via discord or steam $50 gift thingy lel
> [!NOTE]  
> This repository is made for educational purposes and (somewhat) taking part in raising people's aware about internet scamming methods.
> You can learn what's inside and freely distribute non-copyrights materials. This repo, ditto however, may in some chances has copyrighted materials that belong to their respective owners. I am neither responsible nor relating to anything regarding creation of these materials. Caveat emptor.
>
>  **Do not** use this for further scamming attempts. Your actions shall be ruining people's life, therefore if you are thinking about doing so, the world will tell you to halt.
> Also, you should *never* be fallen for these scams and remember to stay safe when browsing online.
>
> This project is inspired by [Discord Datamining](https://github.com/Discord-Datamining/Discord-Datamining). I am quite moved by their attempt to log and dump JS files to seek changes per every discord client update, so I just recreated this idea for a more, or less, other purpose.

### What'll be inside
I plan to scrape pretty anything I could put into, maybe a zip packing the whole website content, extracting shady js files from sus requests, or pretty much more things, neatly organised to each properly-named folders. For more, please look around at the repo.

### How efforts are done
For now I can always make all works done myself in this repo. The method I use to collect websites' datas is fairly simple: just open up your browser's devtool (F12 or Ctrl-Shift-I), navigate to network, refresh the page and select filter by filetype, like this, for example, it is filtered to show only css files:

![image](https://github.com/user-attachments/assets/e089a556-3d63-4a58-9e59-123f98f673c7)

Then right click an item and there are some save to file options. You can choose to save to a single file using the option `Save response as`.  

psst: ctrl-s is the faster way, though it doesn't always ensure the enough-ness.

psst 2: ok now please *don't* do that lmao, follow the guide [here](https://github.com/barnacl437/scampages-datamine/blob/main/archive/type/readme.md), it will tell you how to properly dump a website's contents using wget command.

### ...anything else?
There are various scam shits around on the interwebz. I am still trying to detect and scraping their contents thru many sources, commonly via discord chats or steam pm where some jerks asked me to vote for their team on match.tf lol. 
See this as a hall of shame for every scamming attempts. 

I also have an Internet Archive account where I save what I've found. I've been saving since at least 2021, so how much I've done on here will also have stuff on IArchive taken part in. My plan right now is to import an amount of websites I archived in the past few years on IA. If it catches some of your curiousity right now, you can view my web archive [here](https://archive.org/details/@barnacle555/web-archive). 


obtw... if you are experts or know something about how these shits work, it is greatly appreciated. You can contact me if something's wrong or I seem to need suggestions. Tbh I just barely have much knowledge about full-stack web dev or sysadmin or any craps. I'm doing my best as an amateur collector during leisure times, but may sometimes reveal the amateurness more than what is able to be decent-looking. Thanks a bunch.

### licence
You are free to use, reproduce, redistribute or modify any non-copyrighted materials used in this repository, such as trivial js codes and website templates (if any). The licence doesn't recommend you to sell them and can ask you to use it rationally and ethically as if it would bring benefits to both yourself and people in general.
